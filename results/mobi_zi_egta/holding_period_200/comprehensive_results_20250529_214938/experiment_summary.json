{
  "experiment_summary": {
    "timestamp": "20250529_214938",
    "holding_period": 200,
    "num_equilibria_found": 1,
    "best_equilibrium": {
      "equilibrium_id": 1,
      "regret": 0.0,
      "welfare": 31554.029980281375,
      "mixture_dict": {
        "MELO_0_100": 0.0,
        "MELO_100_0": 1.0
      },
      "mixture_vector": [
        0.0,
        1.0
      ],
      "support": [
        "MELO_100_0"
      ],
      "support_size": 1,
      "is_pure_strategy": true,
      "dominant_strategy": "MELO_100_0",
      "dominant_probability": 1.0
    },
    "predominant_strategy": "MELO_100_0",
    "strategy_frequencies": {
      "MELO_0_100": 0.0,
      "MELO_100_0": 1.0
    }
  },
  "key_findings": [
    "Found 1 equilibria",
    "Best equilibrium has regret 0.000000",
    "Dominant strategy: MELO_100_0 (100.0%)",
    "Best equilibrium is a pure strategy"
  ],
  "files_generated": [
    "experiment_parameters.json",
    "equilibria_detailed.json",
    "equilibria_summary.csv",
    "welfare_analysis.json",
    "game_details.json",
    "raw_payoff_data.json"
  ]
}